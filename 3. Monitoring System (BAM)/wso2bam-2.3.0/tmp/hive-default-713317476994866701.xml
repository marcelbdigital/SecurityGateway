<?xml version="1.0" encoding="UTF-8"?><configuration>
<property><name>hive.ppd.remove.duplicatefilters</name><value>true</value></property>
<property><name>hadoop.bin.path</name><value>null/bin/hadoop</value></property>
<property><name>hive.skewjoin.mapjoin.map.tasks</name><value>10000</value></property>
<property><name>hive.stats.jdbc.timeout</name><value>30</value></property>
<property><name>io.bytes.per.checksum</name><value>512</value></property>
<property><name>hive.hwi.listen.port</name><value>9999</value></property>
<property><name>hive.skewjoin.key</name><value>100000</value></property>
<property><name>hadoop.embedded.local.mode</name><value>true</value></property>
<property><name>javax.jdo.option.ConnectionURL</name><value>jdbc:derby:;databaseName=metastore_db;create=true</value></property>
<property><name>mapred.reduce.tasks.speculative.execution</name><value>true</value></property>
<property><name>hive.lockmgr.zookeeper.default.partition.name</name><value>__HIVE_DEFAULT_ZOOKEEPER_PARTITION__</value></property>
<property><name>hive.mapred.mode</name><value>nonstrict</value></property>
<property><name>hive.metastore.ds.retry.attempts</name><value>1</value></property>
<property><name>io.seqfile.sorter.recordlimit</name><value>1000000</value></property>
<property><name>hive.outerjoin.supports.filters</name><value>true</value></property>
<property><name>hive.exec.job.debug.timeout</name><value>30000</value></property>
<property><name>datanucleus.autoStartMechanismMode</name><value>checked</value></property>
<property><name>hive.intermediate.compression.type</name><value/></property>
<property><name>hadoop.embedded.local.mode.trace.enable</name><value>false</value></property>
<property><name>datanucleus.identifierFactory</name><value>datanucleus</value></property>
<property><name>fs.ramfs.impl</name><value>org.apache.hadoop.fs.InMemoryFileSystem</value></property>
<property><name>hive.mapjoin.followby.gby.localtask.max.memory.usage</name><value>0.55</value></property>
<property><name>hive.metastore.archive.intermediate.archived</name><value>_INTERMEDIATE_ARCHIVED</value></property>
<property><name>hive.input.format</name><value>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</value></property>
<property><name>fs.trash.interval</name><value>0</value></property>
<property><name>hive.index.compact.query.max.entries</name><value>10000000</value></property>
<property><name>hive.metastore.event.clean.freq</name><value>0</value></property>
<property><name>hive.heartbeat.interval</name><value>1000</value></property>
<property><name>hive.session.silent</name><value>false</value></property>
<property><name>hive.metastore.server.min.threads</name><value>200</value></property>
<property><name>mapred.min.split.size.per.rack</name><value>1</value></property>
<property><name>hive.cli.print.current.db</name><value>false</value></property>
<property><name>hive.skewjoin.mapjoin.min.split</name><value>33554432</value></property>
<property><name>hive.ppd.recognizetransivity</name><value>true</value></property>
<property><name>hive.client.stats.publishers</name><value/></property>
<property><name>hive.merge.current.job.has.dynamic.partitions</name><value>false</value></property>
<property><name>hive.script.serde</name><value>org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</value></property>
<property><name>hive.cli.print.header</name><value>false</value></property>
<property><name>javax.jdo.PersistenceManagerFactoryClass</name><value>org.datanucleus.jdo.JDOPersistenceManagerFactory</value></property>
<property><name>datanucleus.validateConstraints</name><value>false</value></property>
<property><name>hive.insert.into.multilevel.dirs</name><value>false</value></property>
<property><name>hive.map.aggr.hash.min.reduction</name><value>0.5</value></property>
<property><name>hive.exec.max.dynamic.partitions</name><value>1000</value></property>
<property><name>hive.limit.optimize.enable</name><value>false</value></property>
<property><name>hive.variable.substitute</name><value>true</value></property>
<property><name>hadoop.security.authorization</name><value>false</value></property>
<property><name>hive.query.result.fileformat</name><value>TextFile</value></property>
<property><name>hive.zookeeper.session.timeout</name><value>600000</value></property>
<property><name>hive.jar.path</name><value/></property>
<property><name>hive.merge.mapredfiles</name><value>false</value></property>
<property><name>hive.stats.default.aggregator</name><value/></property>
<property><name>hive.mapjoin.smalltable.filesize</name><value>25000000</value></property>
<property><name>hive.join.emit.interval</name><value>1000</value></property>
<property><name>hive.start.cleanup.scratchdir</name><value>false</value></property>
<property><name>hive.enforce.bucketing</name><value>false</value></property>
<property><name>hive.merge.input.format.block.level</name><value>org.apache.hadoop.hive.ql.io.rcfile.merge.RCFileBlockMergeInputFormat</value></property>
<property><name>hive.optimize.ppd.storage</name><value>true</value></property>
<property><name>datanucleus.connectionPoolingType</name><value>DBCP</value></property>
<property><name>hive.index.compact.query.max.size</name><value>10737418240</value></property>
<property><name>hive.optimize.index.filter.compact.minsize</name><value>5368709120</value></property>
<property><name>hive.security.authorization.manager</name><value>org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider</value></property>
<property><name>hive.error.on.empty.partition</name><value>false</value></property>
<property><name>hive.mapper.cannot.span.multiple.partitions</name><value>false</value></property>
<property><name>javax.jdo.option.ConnectionDriverName</name><value>org.apache.derby.jdbc.EmbeddedDriver</value></property>
<property><name>hadoop.security.uid.cache.secs</name><value>14400</value></property>
<property><name>hive.optimize.skewjoin</name><value>false</value></property>
<property><name>javax.jdo.option.DetachAllOnCommit</name><value>true</value></property>
<property><name>fs.har.impl.disable.cache</name><value>true</value></property>
<property><name>hive.query.planid</name><value/></property>
<property><name>hive.metastore.ds.retry.interval</name><value>1000</value></property>
<property><name>hive.exec.show.job.failure.debug.info</name><value>true</value></property>
<property><name>hive.script.recordwriter</name><value>org.apache.hadoop.hive.ql.exec.TextRecordWriter</value></property>
<property><name>hive.intermediate.compression.codec</name><value/></property>
<property><name>hive.merge.size.per.task</name><value>256000000</value></property>
<property><name>fs.checkpoint.dir</name><value>${hadoop.tmp.dir}/dfs/namesecondary</value></property>
<property><name>hive.added.archives.path</name><value/></property>
<property><name>javax.jdo.option.ConnectionUserName</name><value>APP</value></property>
<property><name>fs.s3n.impl</name><value>org.apache.hadoop.fs.s3native.NativeS3FileSystem</value></property>
<property><name>hive.join.cache.size</name><value>25000</value></property>
<property><name>datanucleus.transactionIsolation</name><value>read-committed</value></property>
<property><name>hive.limit.optimize.fetch.max</name><value>50000</value></property>
<property><name>hive.exec.mode.local.auto.inputbytes.max</name><value>134217728</value></property>
<property><name>hive.mapred.reduce.tasks.speculative.execution</name><value>true</value></property>
<property><name>hive.metastore.batch.retrieve.max</name><value>300</value></property>
<property><name>hadoop.logfile.size</name><value>10000000</value></property>
<property><name>hive.mapjoin.size.key</name><value>10000</value></property>
<property><name>ipc.client.connection.maxidletime</name><value>10000</value></property>
<property><name>mapred.max.split.size</name><value>256000000</value></property>
<property><name>hive.metastore.warehouse.dir</name><value>/user/hive/warehouse</value></property>
<property><name>hive.io.exception.handlers</name><value/></property>
<property><name>hive.exec.parallel.thread.number</name><value>8</value></property>
<property><name>hive.zookeeper.namespace</name><value>hive_zookeeper_namespace</value></property>
<property><name>fs.checkpoint.size</name><value>67108864</value></property>
<property><name>hive.map.aggr.hash.force.flush.memory.threshold</name><value>0.9</value></property>
<property><name>fs.s3.sleepTimeSeconds</name><value>10</value></property>
<property><name>hive.added.files.path</name><value/></property>
<property><name>hadoop.config.dir</name><value>null/conf</value></property>
<property><name>hive.optimize.metadataonly</name><value>true</value></property>
<property><name>mapred.reduce.tasks</name><value>-1</value></property>
<property><name>io.seqfile.lazydecompress</name><value>true</value></property>
<property><name>hive.exec.drop.ignorenonexistent</name><value>true</value></property>
<property><name>hive.test.mode.nosamplelist</name><value/></property>
<property><name>hive.udtf.auto.progress</name><value>false</value></property>
<property><name>hive.test.mode.prefix</name><value>test_</value></property>
<property><name>ipc.client.tcpnodelay</name><value>false</value></property>
<property><name>hive.optimize.reducededuplication</name><value>true</value></property>
<property><name>hive.query.id</name><value/></property>
<property><name>hive.mapjoin.localtask.max.memory.usage</name><value>0.9</value></property>
<property><name>hive.limit.row.max.size</name><value>100000</value></property>
<property><name>hive.querylog.location</name><value>/tmp/marcel</value></property>
<property><name>hive.mapjoin.followby.map.aggr.hash.percentmemory</name><value>0.3</value></property>
<property><name>io.compression.codecs</name><value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec</value></property>
<property><name>hive.optimize.index.filter</name><value>false</value></property>
<property><name>io.file.buffer.size</name><value>4096</value></property>
<property><name>hive.exec.script.maxerrsize</name><value>100000</value></property>
<property><name>hive.security.authorization.createtable.owner.grants</name><value/></property>
<property><name>hive.hadoop.supports.splittable.combineinputformat</name><value>false</value></property>
<property><name>hive.table.name</name><value/></property>
<property><name>hive.exec.perf.logger</name><value>org.apache.hadoop.hive.ql.log.PerfLogger</value></property>
<property><name>hive.security.authorization.createtable.user.grants</name><value/></property>
<property><name>hive.metastore.execute.setugi</name><value>false</value></property>
<property><name>fs.har.impl</name><value>org.apache.hadoop.hive.shims.HiveHarFileSystem</value></property>
<property><name>hadoop.security.authentication</name><value>simple</value></property>
<property><name>fs.s3.buffer.dir</name><value>${hadoop.tmp.dir}/s3</value></property>
<property><name>hive.metastore.partition.inherit.table.properties</name><value/></property>
<property><name>hive.partition.name</name><value/></property>
<property><name>hive.optimize.groupby</name><value>true</value></property>
<property><name>hive.exec.tasklog.debug.timeout</name><value>20000</value></property>
<property><name>javax.jdo.option.NonTransactionalRead</name><value>true</value></property>
<property><name>hive.stats.atomic</name><value>false</value></property>
<property><name>hive.metastore.connect.retries</name><value>5</value></property>
<property><name>hive.stats.default.publisher</name><value/></property>
<property><name>hive.exec.post.hooks</name><value/></property>
<property><name>hive.exec.dynamic.partition</name><value>false</value></property>
<property><name>hive.stats.dbconnectionstring</name><value>jdbc:derby:;databaseName=TempStatsStore;create=true</value></property>
<property><name>fs.file.impl</name><value>org.apache.hadoop.fs.LocalFileSystem</value></property>
<property><name>hive.security.authenticator.manager</name><value>org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator</value></property>
<property><name>hive.client.stats.counters</name><value/></property>
<property><name>ipc.client.kill.max</name><value>10</value></property>
<property><name>hive.lock.sleep.between.retries</name><value>60</value></property>
<property><name>hive.exec.reducers.max</name><value>999</value></property>
<property><name>hive.jobname.length</name><value>50</value></property>
<property><name>hive.limit.optimize.limit.file</name><value>10</value></property>
<property><name>datanucleus.cache.level2</name><value>false</value></property>
<property><name>hive.security.authorization.enabled</name><value>false</value></property>
<property><name>hive.alias</name><value/></property>
<property><name>hive.optimize.index.autoupdate</name><value>false</value></property>
<property><name>ipc.server.listen.queue.size</name><value>128</value></property>
<property><name>hive.metastore.authorization.storage.checks</name><value>false</value></property>
<property><name>hive.script.operator.id.env.var</name><value>HIVE_SCRIPT_OPERATOR_ID</value></property>
<property><name>io.mapfile.bloom.size</name><value>1048576</value></property>
<property><name>fs.hsftp.impl</name><value>org.apache.hadoop.hdfs.HsftpFileSystem</value></property>
<property><name>hive.metastore.rawstore.impl</name><value>org.apache.hadoop.hive.metastore.ObjectStore</value></property>
<property><name>hive.stats.retries.max</name><value>0</value></property>
<property><name>hive.exec.dynamic.partition.mode</name><value>strict</value></property>
<property><name>hive.security.authorization.createtable.role.grants</name><value/></property>
<property><name>hadoop.util.hash.type</name><value>murmur</value></property>
<property><name>topology.node.switch.mapping.impl</name><value>org.apache.hadoop.net.ScriptBasedMapping</value></property>
<property><name>hive.fetch.output.serde</name><value>org.apache.hadoop.hive.serde2.DelimitedJSONSerDe</value></property>
<property><name>hive.sample.seednumber</name><value>0</value></property>
<property><name>hive.metastore.fs.handler.class</name><value>org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl</value></property>
<property><name>hive.enforce.sorting</name><value>false</value></property>
<property><name>hive.hashtable.loadfactor</name><value>0.75</value></property>
<property><name>hive.exec.failure.hooks</name><value/></property>
<property><name>hive.metastore.server.tcp.keepalive</name><value>true</value></property>
<property><name>fs.s3.maxRetries</name><value>4</value></property>
<property><name>hive.script.auto.progress</name><value>false</value></property>
<property><name>hive.mapred.local.mem</name><value>0</value></property>
<property><name>hive.metastore.kerberos.principal</name><value>hive-metastore/_HOST@EXAMPLE.COM</value></property>
<property><name>hive.retain.query.logs</name><value>false</value></property>
<property><name>hive.optimize.ppd</name><value>true</value></property>
<property><name>hadoop.rpc.socket.factory.class.default</name><value>org.apache.hadoop.net.StandardSocketFactory</value></property>
<property><name>mapred.input.dir.recursive</name><value>false</value></property>
<property><name>hive.exec.plan</name><value/></property>
<property><name>fs.hftp.impl</name><value>org.apache.hadoop.hdfs.HftpFileSystem</value></property>
<property><name>hive.exec.parallel</name><value>false</value></property>
<property><name>hive.metastore.ds.connection.url.hook</name><value/></property>
<property><name>hive.exec.max.created.files</name><value>100000</value></property>
<property><name>fs.kfs.impl</name><value>org.apache.hadoop.fs.kfs.KosmosFileSystem</value></property>
<property><name>hive.stats.jdbcdriver</name><value>org.apache.derby.jdbc.EmbeddedDriver</value></property>
<property><name>hive.script.recordreader</name><value>org.apache.hadoop.hive.ql.exec.TextRecordReader</value></property>
<property><name>fs.hdfs.impl</name><value>org.apache.hadoop.hdfs.DistributedFileSystem</value></property>
<property><name>hive.security.authorization.createtable.group.grants</name><value/></property>
<property><name>hive.index.compact.binary.search</name><value>true</value></property>
<property><name>hive.mergejob.maponly</name><value>true</value></property>
<property><name>hive.auto.progress.timeout</name><value>0</value></property>
<property><name>hive.optimize.index.filter.compact.maxsize</name><value>-1</value></property>
<property><name>javax.jdo.option.ConnectionPassword</name><value>mine</value></property>
<property><name>hive.mapjoin.cache.numrows</name><value>25000</value></property>
<property><name>hive.metastore.archive.intermediate.original</name><value>_INTERMEDIATE_ORIGINAL</value></property>
<property><name>mapred.min.split.size</name><value>1</value></property>
<property><name>hive.groupby.mapaggr.checkinterval</name><value>100000</value></property>
<property><name>fs.ftp.impl</name><value>org.apache.hadoop.fs.ftp.FTPFileSystem</value></property>
<property><name>hive.metastore.cache.pinobjtypes</name><value>Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order</value></property>
<property><name>hive.multigroupby.singlemr</name><value>false</value></property>
<property><name>hive.stats.collect.rawdatasize</name><value>true</value></property>
<property><name>datanucleus.plugin.pluginRegistryBundleCheck</name><value>LOG</value></property>
<property><name>hive.exec.rowoffset</name><value>false</value></property>
<property><name>hive.metastore.server.max.threads</name><value>100000</value></property>
<property><name>local.cache.size</name><value>10737418240</value></property>
<property><name>hive.archive.har.parentdir.settable</name><value>false</value></property>
<property><name>hive.exec.reducers.bytes.per.reducer</name><value>1000000000</value></property>
<property><name>hive.hwi.listen.host</name><value>0.0.0.0</value></property>
<property><name>hive.exec.mode.local.auto</name><value>false</value></property>
<property><name>hive.exec.script.trust</name><value>false</value></property>
<property><name>hive.downloaded.resources.dir</name><value>/tmp/marcel/hive_resources</value></property>
<property><name>hive.metastore.force.reload.conf</name><value>false</value></property>
<property><name>hive.aux.jars.path</name><value/></property>
<property><name>hive.archive.enabled</name><value>false</value></property>
<property><name>hive.metastore.client.connect.retry.delay</name><value>1</value></property>
<property><name>hive.metastore.kerberos.keytab.file</name><value/></property>
<property><name>datanucleus.autoCreateSchema</name><value>true</value></property>
<property><name>hive.zookeeper.quorum</name><value/></property>
<property><name>hive.metastore.local</name><value>true</value></property>
<property><name>hive.semantic.analyzer.hook</name><value/></property>
<property><name>hive.lock.manager</name><value>org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager</value></property>
<property><name>hive.exec.submitviachild</name><value>false</value></property>
<property><name>hive.merge.mapfiles</name><value>true</value></property>
<property><name>ipc.client.idlethreshold</name><value>4000</value></property>
<property><name>hive.exec.concatenate.check.index</name><value>true</value></property>
<property><name>ipc.server.tcpnodelay</name><value>false</value></property>
<property><name>hadoop.logfile.count</name><value>10</value></property>
<property><name>hive.zookeeper.clean.extra.nodes</name><value>false</value></property>
<property><name>hive.support.concurrency</name><value>false</value></property>
<property><name>hive.exec.default.partition.name</name><value>__HIVE_DEFAULT_PARTITION__</value></property>
<property><name>hive.cli.errors.ignore</name><value>false</value></property>
<property><name>hive.debug.localtask</name><value>false</value></property>
<property><name>fs.s3.block.size</name><value>67108864</value></property>
<property><name>hive.unlock.numretries</name><value>10</value></property>
<property><name>hive.exec.counters.pull.interval</name><value>1000</value></property>
<property><name>hive.groupby.skewindata</name><value>false</value></property>
<property><name>hive.metastore.metadb.dir</name><value/></property>
<property><name>datanucleus.cache.level2.type</name><value>SOFT</value></property>
<property><name>hive.mapred.partitioner</name><value>org.apache.hadoop.hive.ql.io.DefaultHivePartitioner</value></property>
<property><name>hive.zookeeper.client.port</name><value>2181</value></property>
<property><name>hive.mapjoin.check.memory.rows</name><value>100000</value></property>
<property><name>hive.index.compact.file.ignore.hdfs</name><value>false</value></property>
<property><name>hive.task.progress</name><value>false</value></property>
<property><name>hive.stats.dbclass</name><value>jdbc:derby</value></property>
<property><name>datanucleus.storeManagerType</name><value>rdbms</value></property>
<property><name>hive.exec.pre.hooks</name><value/></property>
<property><name>hive.session.id</name><value/></property>
<property><name>hive.optimize.cp</name><value>true</value></property>
<property><name>hive.exec.mode.local.auto.tasks.max</name><value>4</value></property>
<property><name>io.serializations</name><value>org.apache.hadoop.io.serializer.WritableSerialization</value></property>
<property><name>hive.metastore.event.expiry.duration</name><value>0</value></property>
<property><name>hive.exim.uri.scheme.whitelist</name><value>hdfs,pfile</value></property>
<property><name>javax.jdo.option.Multithreaded</name><value>true</value></property>
<property><name>io.seqfile.compress.blocksize</name><value>1000000</value></property>
<property><name>hive.table.parameters.default</name><value/></property>
<property><name>ipc.client.connect.max.retries</name><value>10</value></property>
<property><name>webinterface.private.actions</name><value>false</value></property>
<property><name>hive.optimize.index.groupby</name><value>false</value></property>
<property><name>hive.map.aggr</name><value>true</value></property>
<property><name>fs.checkpoint.edits.dir</name><value>${fs.checkpoint.dir}</value></property>
<property><name>datanucleus.validateTables</name><value>false</value></property>
<property><name>hive.exec.scratchdir</name><value>/tmp/hive-marcel</value></property>
<property><name>hive.test.mode.samplefreq</name><value>32</value></property>
<property><name>hive.optimize.bucketmapjoin.sortedmerge</name><value>false</value></property>
<property><name>hive.exec.max.dynamic.partitions.pernode</name><value>100</value></property>
<property><name>hadoop.security.group.mapping</name><value>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</value></property>
<property><name>hive.metastore.archive.intermediate.extracted</name><value>_INTERMEDIATE_EXTRACTED</value></property>
<property><name>hive.stats.autogather</name><value>true</value></property>
<property><name>hive.rework.mapredwork</name><value>false</value></property>
<property><name>fs.s3.impl</name><value>org.apache.hadoop.fs.s3.S3FileSystem</value></property>
<property><name>hive.exec.script.allow.partial.consumption</name><value>false</value></property>
<property><name>hive.autogen.columnalias.prefix.label</name><value>_c</value></property>
<property><name>hive.auto.convert.join</name><value>false</value></property>
<property><name>hive.exec.compress.output</name><value>false</value></property>
<property><name>hadoop.tmp.dir</name><value>/tmp/hadoop-${user.name}</value></property>
<property><name>mapred.min.split.size.per.node</name><value>1</value></property>
<property><name>topology.script.number.args</name><value>100</value></property>
<property><name>fs.default.name</name><value>file:///</value></property>
<property><name>hive.metastore.sasl.enabled</name><value>false</value></property>
<property><name>hive.metastore.event.listeners</name><value/></property>
<property><name>hive.hbase.wal.enabled</name><value>true</value></property>
<property><name>hive.hashtable.initialCapacity</name><value>100000</value></property>
<property><name>hive.test.mode</name><value>false</value></property>
<property><name>hive.stats.retries.wait</name><value>3000</value></property>
<property><name>hive.added.jars.path</name><value/></property>
<property><name>hive.optimize.bucketmapjoin</name><value>false</value></property>
<property><name>datanucleus.validateColumns</name><value>false</value></property>
<property><name>hive.mapjoin.bucket.cache.size</name><value>100</value></property>
<property><name>hive.metastore.client.socket.timeout</name><value>20</value></property>
<property><name>io.mapfile.bloom.error.rate</name><value>0.005</value></property>
<property><name>hive.map.aggr.hash.percentmemory</name><value>0.5</value></property>
<property><name>hive.lock.mapred.only.operation</name><value>false</value></property>
<property><name>hive.merge.rcfile.block.level</name><value>true</value></property>
<property><name>hive.metastore.uris</name><value/></property>
<property><name>hive.autogen.columnalias.prefix.includefuncname</name><value>false</value></property>
<property><name>fs.checkpoint.period</name><value>3600</value></property>
<property><name>hive.exec.compress.intermediate</name><value>false</value></property>
<property><name>hive.lock.numretries</name><value>100</value></property>
<property><name>hive.default.fileformat</name><value>TextFile</value></property>
<property><name>hive.metastore.end.function.listeners</name><value/></property>
<property><name>io.skip.checksum.errors</name><value>false</value></property>
<property><name>hive.current.tenant</name><value>-1234</value></property>
<property><name>hadoop.embedded.local.mode.debug</name><value>false</value></property>
<property><name>hive.fileformat.check</name><value>true</value></property>
<property><name>hadoop.native.lib</name><value>true</value></property>
<property><name>hive.merge.smallfiles.avgsize</name><value>16000000</value></property>
<property><name>hive.query.string</name><value/></property>
</configuration>